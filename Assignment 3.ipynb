{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '''A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points. Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points. Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "import transformers\n",
    "import spacy\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.compat.v1 as tf\n",
    "from spacy import displacy\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences :\n",
      "['A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic.', 'Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs.', 'This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.', 'Paragraphs can contain many different kinds of information.', 'A paragraph could contain a series of brief examples or a single long illustration of a general point.', 'It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects.', 'Regardless of the kind of information they contain, all paragraphs share certain characteristics.', 'One of the most important of these is a topic sentence.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert paragraph into list of sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "raw_sentences = tokenizer.tokenize(string.strip())\n",
    "sentences = [sentence for sentence in raw_sentences if len(sentence) > 0]\n",
    "print('Sentences :')\n",
    "print(sentences, end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for word \"sentence\" : \n",
      "[ 5.1207771e-03 -4.4107656e-03 -9.2051858e-03 -9.0583870e-03\n",
      "  6.2181242e-03 -5.2418937e-03  5.2688741e-03 -1.5554887e-03\n",
      "  9.6765831e-03  7.1525103e-03  9.8813595e-03  8.3572073e-03\n",
      " -7.8599807e-03 -9.5791658e-03 -5.5657760e-03 -8.1351801e-04\n",
      "  5.0154519e-03  3.6702869e-03 -2.0397545e-03  5.0118039e-03\n",
      " -3.3978079e-03 -6.7980345e-03  4.7297091e-03 -9.8678144e-03\n",
      "  8.8420842e-04 -5.0069601e-03  7.5918878e-03 -3.7404767e-03\n",
      "  2.8073478e-03 -6.2389341e-03  9.6416324e-03 -5.5988207e-03\n",
      "  3.6009781e-03  3.2136077e-03  8.9124087e-03 -5.5417670e-03\n",
      " -4.3727458e-03 -6.2086955e-03  6.1387308e-03 -4.5998693e-03\n",
      "  4.8208917e-03 -8.9610508e-04  7.2694193e-03 -6.0103405e-03\n",
      " -7.9307887e-05 -1.0296506e-04 -8.5515967e-03  8.7202508e-03\n",
      " -2.0959489e-03  6.4399657e-03  9.4515606e-05  5.0101718e-03\n",
      "  2.2122220e-03  8.8246176e-03 -8.3458591e-03  8.4297704e-03\n",
      "  8.6530289e-03  1.0469728e-03  4.4118296e-03  3.8222342e-03\n",
      "  4.0765288e-03 -2.9526122e-03  2.8707823e-03  7.7564525e-04\n",
      "  4.8101135e-03  8.4452480e-03 -7.7527082e-03  1.6675923e-04\n",
      " -8.7701473e-03 -1.5574223e-03 -9.0360623e-03  3.1846662e-03\n",
      " -1.5591375e-03 -6.9172174e-04  6.4529576e-03 -8.0745257e-03\n",
      "  1.1611532e-03 -2.4123508e-03 -3.7323390e-03 -7.2852783e-03\n",
      " -7.9815565e-03  8.2607549e-03 -7.4675446e-03  4.8175538e-03\n",
      " -3.7990760e-03 -1.2381093e-03  2.8339559e-03 -8.5898163e-03\n",
      " -5.6539010e-03 -7.7250367e-03 -9.3990518e-03 -4.7386289e-03\n",
      " -3.1561761e-03  4.9404823e-04 -6.7791843e-04 -7.8799212e-03\n",
      " -3.7778120e-03 -2.7351975e-03 -6.3781603e-03 -6.3872109e-03]\n"
     ]
    }
   ],
   "source": [
    "# 1.i) Word2Vec\n",
    "\n",
    "wordvecs = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "stop_words = list(set(stopwords.words(\"english\")))\n",
    "\n",
    "for sentence in wordvecs:\n",
    "    for word in sentence:\n",
    "        if word in stop_words:\n",
    "            sentence.remove(word)\n",
    "\n",
    "model = Word2Vec(wordvecs, min_count=1)\n",
    "\n",
    "# Vector for word 'sentence'\n",
    "print('Vector for word \"sentence\" : ')\n",
    "print(model.wv['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.01168494 -0.03060572  0.06116334 ... -0.08641756  0.00025049\n",
      "   0.05482749]\n",
      " [ 0.02972509 -0.03655469  0.08002593 ... -0.07038907 -0.02832131\n",
      "   0.04804677]\n",
      " [ 0.07221662 -0.04182237  0.05336685 ... -0.06942353  0.01795928\n",
      "   0.06641504]\n",
      " ...\n",
      " [ 0.01586944 -0.05243037  0.06065089 ... -0.0643559   0.04215747\n",
      "   0.06304203]\n",
      " [ 0.04141244  0.02588909 -0.00625631 ... -0.02162989  0.00910817\n",
      "   0.03623574]\n",
      " [ 0.01578411 -0.02142679  0.00402448 ... -0.09605587 -0.06707881\n",
      "   0.07970382]], shape=(8, 512), dtype=float32) \n",
      "\n",
      "\n",
      "Sentence :\n",
      "A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic.\n",
      "Converted to :\n",
      "tf.Tensor(\n",
      "[ 1.16849439e-02 -3.06057241e-02  6.11633360e-02  8.47723708e-02\n",
      " -5.83404116e-03  2.84160231e-03  2.59479377e-02  3.90260434e-03\n",
      " -5.55586144e-02  5.68111017e-02 -8.95013753e-03 -4.50469833e-03\n",
      " -6.06310330e-02  3.18566412e-02 -6.86047673e-02 -9.39451456e-02\n",
      " -4.23613563e-02  3.93057056e-02 -9.02280435e-02 -5.53664081e-02\n",
      " -1.92777300e-03  5.99909797e-02  9.42119956e-03  6.07980005e-02\n",
      " -5.22597926e-03  1.28727918e-02 -2.15456709e-02 -4.93354201e-02\n",
      " -6.26553228e-05 -4.05308716e-02  7.90260881e-02 -5.32253738e-03\n",
      " -2.70439382e-03 -1.01282820e-02 -6.41689152e-02  2.35940609e-02\n",
      "  4.94743176e-02  1.76912546e-02 -7.69227697e-03  2.03443412e-02\n",
      "  1.55387633e-02  4.64376062e-02  3.61865349e-02  4.38465290e-02\n",
      "  6.95741251e-02  2.37604566e-02 -1.20335293e-03 -4.55583632e-02\n",
      " -3.44719328e-02  1.63743496e-02 -2.70779734e-03  5.60244359e-02\n",
      "  4.04611463e-04 -1.96648836e-02 -3.91405039e-02 -9.61554609e-03\n",
      "  2.14325567e-03  5.61526977e-02  2.82766856e-02  1.80720370e-02\n",
      "  1.23768335e-03 -3.25147919e-02  4.19939682e-02  6.37653396e-02\n",
      "  5.56223206e-02  1.44277094e-02  4.99183051e-02 -1.93575360e-02\n",
      "  5.64282723e-02 -6.90749884e-02  1.60084246e-03  2.10034288e-02\n",
      "  3.52526940e-02  6.35947958e-02 -7.65628293e-02  5.87279461e-02\n",
      " -4.10689153e-02  3.31177711e-02 -2.83573032e-03  7.48986006e-03\n",
      " -3.19784060e-02 -6.25580475e-02  4.89425138e-02  3.36479954e-02\n",
      "  2.12714784e-02  4.28449037e-03 -9.05702938e-04 -4.36471775e-03\n",
      " -9.23611522e-02 -3.89573984e-02  3.30829062e-02  9.61312652e-03\n",
      "  2.15857383e-02 -1.47692608e-02  1.38847381e-02  8.47374573e-02\n",
      " -8.47435743e-02 -4.44485173e-02  7.54610673e-02  1.65129546e-02\n",
      "  2.31740214e-02 -2.84717046e-02 -6.77682683e-02  4.24248502e-02\n",
      " -1.49503695e-02  8.38017184e-03  5.18886149e-02  3.92066427e-02\n",
      " -4.66535538e-02 -2.45939065e-02  7.14558701e-04 -3.46494373e-03\n",
      "  2.36652400e-02  3.31293605e-02 -5.71687194e-03  4.09858935e-02\n",
      " -8.35536122e-02 -1.66684482e-02 -3.52721172e-03  1.73547976e-02\n",
      "  2.53550690e-02 -2.66782790e-02 -2.51310170e-02 -4.68712412e-02\n",
      "  3.96435596e-02 -6.68356707e-03 -3.46517675e-02 -2.81814691e-02\n",
      "  4.19962518e-02 -3.24101411e-02  2.40438562e-02 -5.47123840e-03\n",
      "  2.89680026e-02  6.99753165e-02  3.75228748e-02 -8.82184058e-02\n",
      "  6.07019942e-03 -6.91123381e-02 -1.74329504e-02  2.53294241e-02\n",
      " -7.28369728e-02  2.37329323e-02  4.66295630e-02  4.23278399e-02\n",
      "  5.21277003e-02 -3.55557445e-03 -1.40108056e-02  2.05670893e-02\n",
      "  7.19132945e-02 -7.66954198e-02 -3.90845127e-02 -6.40899613e-02\n",
      "  2.43546981e-02  7.42070898e-02  2.84558274e-02 -7.93435127e-02\n",
      " -1.47222299e-02  6.70734374e-03  1.02058509e-02  1.25844311e-02\n",
      "  3.10074352e-02 -4.17215079e-02  6.03259206e-02  6.22179657e-02\n",
      "  2.10032985e-02 -1.65604483e-02  4.09300625e-03 -3.35808396e-02\n",
      "  7.28031546e-02  6.09729029e-02  4.15964285e-03  8.54913443e-02\n",
      "  1.31301237e-02 -6.34361152e-03 -5.07236160e-02  7.03543574e-02\n",
      "  3.73295620e-02  3.42008248e-02 -3.79248231e-05 -6.27389476e-02\n",
      "  4.80308905e-02 -2.81623453e-02 -7.19844922e-02  1.20989699e-02\n",
      " -4.26681936e-02  1.97790880e-02 -1.35227852e-02 -5.43040819e-02\n",
      " -4.83289771e-02 -2.65408643e-02  8.23441967e-02  5.54602556e-02\n",
      "  7.81148672e-02 -4.00116201e-03  2.02439521e-02  1.84899904e-02\n",
      " -1.52465580e-02  2.18962673e-02  3.17285024e-02  7.06312209e-02\n",
      "  3.70560354e-03  2.40870714e-02  1.94732740e-03 -7.16166059e-03\n",
      " -2.68035103e-02  3.17232162e-02  8.41562971e-02  2.63580158e-02\n",
      " -2.52104346e-02 -1.10670784e-02 -5.61277084e-02  3.97370756e-02\n",
      " -5.51151559e-02  6.12288788e-02  5.18368408e-02 -1.64934266e-02\n",
      "  1.84758252e-03  6.83429018e-02  6.94626123e-02  3.78927253e-02\n",
      " -5.02522662e-02 -2.57219467e-02  7.02316985e-02  3.36491726e-02\n",
      "  5.98843151e-04 -3.67770121e-02  4.44350131e-02  1.09023610e-02\n",
      "  4.34661582e-02 -6.98098615e-02 -2.62660235e-02  2.23396812e-02\n",
      "  9.15533770e-03 -6.15917593e-02  8.41568485e-02  3.92306261e-02\n",
      "  8.92866924e-02  1.28771095e-02  1.39245279e-02 -5.68395071e-02\n",
      " -7.46639073e-02  3.65591720e-02  1.06103532e-02 -6.25316650e-02\n",
      "  1.77653562e-02 -6.67558014e-02 -6.54299408e-02  4.47695479e-02\n",
      " -2.96408013e-02 -2.13828012e-02  3.60825025e-02 -8.18173215e-02\n",
      " -1.40964817e-02  1.33901071e-02  3.07124332e-02 -9.41405594e-02\n",
      "  3.03545352e-02 -2.68576313e-02  1.81658119e-02 -3.67770456e-02\n",
      "  3.33085321e-02  9.13278013e-02 -1.94911361e-02 -1.07954638e-02\n",
      " -9.28003434e-03 -4.06912202e-03  1.46724554e-02 -4.92432751e-02\n",
      "  1.71533711e-02 -5.45221679e-02 -6.61363900e-02 -7.90792033e-02\n",
      "  2.79751867e-02  3.62354144e-02  4.38262150e-02  1.96567923e-02\n",
      " -6.87819868e-02  2.44918931e-02  7.10261539e-02  9.12545174e-02\n",
      "  6.29523098e-02  1.67941246e-02  6.54825941e-02 -4.73536598e-03\n",
      " -4.48028147e-02 -1.61742885e-02  2.20355578e-02 -4.16113362e-02\n",
      "  1.13562504e-02 -3.63931991e-02 -2.76283920e-02  2.01357305e-02\n",
      " -8.22386295e-02 -2.58973297e-02 -4.15527336e-02 -5.79356179e-02\n",
      "  7.72937061e-03  4.06588800e-02 -1.13817779e-02  4.38650362e-02\n",
      " -1.07140923e-02 -4.62955013e-02  5.65050691e-02 -6.18267693e-02\n",
      " -3.84526551e-02 -4.90092151e-02  5.23114316e-02 -5.73057793e-02\n",
      " -1.15798209e-02  5.35166217e-03  2.78308727e-02 -4.59580906e-02\n",
      "  4.34778444e-02 -1.71735808e-02 -1.64880138e-02 -3.88848744e-02\n",
      " -6.44620880e-03  8.33479464e-02  3.65923420e-02  2.13971920e-02\n",
      " -2.59777829e-02 -6.10677786e-02  5.17178699e-02 -5.09534739e-02\n",
      " -8.41620937e-02 -2.87301578e-02 -8.05718452e-02  7.76726454e-02\n",
      "  4.12432030e-02 -3.67930271e-02  2.71156430e-02 -6.33788854e-02\n",
      "  2.25471351e-02 -3.28405984e-02 -9.11884382e-03  5.93739860e-02\n",
      " -7.64807360e-03  8.31472967e-03 -6.06926717e-03  6.88906685e-02\n",
      "  5.30840680e-02 -3.67050874e-03 -2.88560782e-02 -4.73021753e-02\n",
      " -9.18376148e-02 -8.83616880e-03  7.96945244e-02  5.93198910e-02\n",
      "  3.53018939e-02  7.12430151e-03 -7.07041547e-02  1.53526310e-02\n",
      "  4.09509540e-02  7.17415195e-03  7.37813264e-02  3.77231054e-02\n",
      " -9.00578946e-02 -3.24093699e-02  1.16494242e-02 -3.81785855e-02\n",
      "  2.34411675e-02 -2.10632719e-02 -7.03862086e-02  1.52056175e-03\n",
      " -1.61061939e-02  6.18526712e-02  7.94101879e-02  5.88112744e-03\n",
      " -1.51091320e-02 -3.21430042e-02  7.52920099e-03 -1.46266189e-03\n",
      "  6.74486309e-02  8.21412131e-02  1.35811539e-02  1.83010437e-02\n",
      "  3.14529538e-02  3.24921273e-02 -1.57691985e-02 -4.33157757e-02\n",
      " -4.35552038e-02 -1.21416906e-02  3.53560923e-03  4.30949889e-02\n",
      " -2.73922943e-02  2.91704331e-02 -8.02248865e-02 -2.86437869e-02\n",
      " -1.37747275e-02 -3.15168686e-02 -1.11740967e-02 -2.86995713e-02\n",
      " -3.92324328e-02  5.84819168e-02  5.46792429e-03 -2.98926122e-02\n",
      "  5.75807877e-03 -1.14696817e-02 -1.36440843e-02  2.66201012e-02\n",
      "  2.02788669e-03  3.45309936e-02 -5.55947274e-02  4.45481129e-02\n",
      "  7.75338849e-03  3.83887663e-02 -3.04163899e-02 -3.68546359e-02\n",
      " -5.83012290e-02  4.55890112e-02  4.12782207e-02 -2.69910377e-02\n",
      "  6.76821470e-02 -4.02726643e-02 -1.81559399e-02 -3.41260284e-02\n",
      "  5.10257035e-02  1.71381626e-02 -4.04660823e-03 -5.73980249e-02\n",
      "  1.24875773e-02 -6.49295151e-02 -7.56197646e-02  1.49736693e-02\n",
      "  2.50920299e-02  6.72384948e-02  5.28012849e-02  9.06193554e-02\n",
      " -5.04058525e-02  4.25336175e-02  2.04153005e-02 -6.48180954e-03\n",
      "  2.96379030e-02  4.65666596e-03 -4.00493965e-02 -5.69047667e-02\n",
      " -1.83908250e-02  2.06823163e-02  3.54513973e-02 -9.10554156e-02\n",
      " -2.56894752e-02  8.05327594e-02 -6.87960312e-02 -1.90876480e-02\n",
      " -4.92980296e-04 -1.21406931e-02 -8.38929508e-03  8.40042438e-03\n",
      "  7.14359283e-02 -1.60705782e-02  5.72944582e-02  3.03891674e-03\n",
      " -6.78497627e-02 -6.15831316e-02  7.88365230e-02 -6.56958222e-02\n",
      "  4.85723242e-02  6.67115822e-02  8.34890753e-02 -5.98137565e-02\n",
      " -1.69116650e-02  8.24893564e-02 -6.09519752e-03 -3.53485346e-02\n",
      " -2.27540974e-02 -9.13803354e-02 -4.53933775e-02 -8.25899187e-03\n",
      "  4.79642823e-02  7.68054426e-02 -3.04625053e-02 -1.50704673e-02\n",
      " -2.30549853e-02 -8.25553574e-03 -6.91696582e-03 -4.25872509e-04\n",
      "  3.37524153e-02 -2.74846312e-02 -9.42038652e-03 -6.28642738e-03\n",
      " -2.22889036e-02 -1.39351804e-02  6.23975787e-03 -8.72642770e-02\n",
      "  1.45548386e-02 -8.02355036e-02 -3.33043039e-02 -5.46392351e-02\n",
      "  4.86492850e-02  2.14733034e-02  3.27530019e-02 -1.53551055e-02\n",
      "  5.31828552e-02  1.56334899e-02  3.91776711e-02  6.98065013e-03\n",
      " -3.86222564e-02 -2.99131218e-02  1.69515181e-02  5.10435551e-02\n",
      "  3.60743515e-02 -5.03288098e-02  5.67543581e-02  7.83906356e-02\n",
      "  6.19171187e-02 -1.52612152e-02 -1.87837481e-02 -3.86124067e-02\n",
      "  6.28505424e-02 -8.64175558e-02  2.50494370e-04  5.48274927e-02], shape=(512,), dtype=float32) \n",
      "\n",
      "\n",
      "Sentence :\n",
      "Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs.\n",
      "Converted to :\n",
      "tf.Tensor(\n",
      "[ 0.02972509 -0.03655469  0.08002593  0.02287604 -0.02667179  0.02675389\n",
      "  0.07385173  0.07387772  0.00344297  0.0615565  -0.01421661 -0.03524254\n",
      " -0.05847446  0.05700279  0.00594968 -0.08057545  0.00383085  0.00520477\n",
      "  0.00106904 -0.02401644 -0.02129655  0.06010127 -0.05534425  0.00727631\n",
      " -0.03931402 -0.00633522  0.00966344 -0.06325465 -0.07747131 -0.01298261\n",
      " -0.037573   -0.01885733  0.02819638  0.00726106 -0.01602999 -0.02466446\n",
      "  0.06610397  0.06278811  0.02846644 -0.01255236 -0.0080745   0.00774304\n",
      "  0.05540441  0.05732685  0.04363765  0.02251689 -0.06711926 -0.05257751\n",
      " -0.0072744  -0.02157244  0.00166901 -0.07300093  0.04060853 -0.04638837\n",
      " -0.05868316  0.0098521  -0.04921524  0.03727904  0.01631238  0.02983114\n",
      " -0.07350341 -0.02681768  0.08564842  0.02193238  0.04542242  0.04971875\n",
      " -0.05848779 -0.05710077  0.0683763  -0.05687222  0.04124265 -0.04729\n",
      "  0.02830315  0.02164796  0.02789934  0.03820241 -0.08752063  0.05860766\n",
      "  0.05308244 -0.06889062 -0.02139433 -0.02491207 -0.0209242   0.0253795\n",
      "  0.00168108  0.01051665  0.02133182 -0.00704854 -0.08912382 -0.05155018\n",
      "  0.03348397  0.05512237  0.02176908 -0.06255658  0.04591915  0.09793776\n",
      " -0.09715818 -0.06321196  0.06535351 -0.09554329 -0.01429102  0.00351913\n",
      " -0.05746915 -0.04086668 -0.03405273 -0.06157103  0.05792288 -0.00342988\n",
      " -0.00026156 -0.02865479 -0.06313821 -0.00309744 -0.01870382  0.04715635\n",
      " -0.00242313 -0.00238533 -0.06354459  0.0302345  -0.02588304 -0.04718013\n",
      " -0.01191311 -0.04766964 -0.04527169 -0.04596619  0.00552473  0.01958744\n",
      " -0.06068758 -0.05092223  0.04927929 -0.03886389  0.07345072 -0.03626851\n",
      " -0.03373666  0.06312011  0.0436017  -0.08496447  0.00232651 -0.03670321\n",
      "  0.00797101  0.05722298 -0.04800618  0.02027796  0.02751364  0.0545282\n",
      " -0.04505731  0.06007593 -0.01326958  0.00336026  0.05255717 -0.05769962\n",
      " -0.04228612 -0.07224746 -0.00543896  0.04229786  0.03959085 -0.05267498\n",
      "  0.02007374 -0.00461791  0.08139773  0.03152775  0.01738843  0.00649814\n",
      "  0.06606878  0.05416894 -0.05785801  0.02081549 -0.02234734  0.00181174\n",
      "  0.0648282  -0.02867479 -0.01527441  0.04817073 -0.06536277  0.04709604\n",
      " -0.03528836  0.05088417 -0.0125709  -0.00915414 -0.01003303 -0.05880003\n",
      "  0.07240985 -0.09302349  0.03752574 -0.02514007  0.06850326  0.00652437\n",
      "  0.00365579  0.04342903 -0.08131152  0.06975103  0.09262232  0.06359179\n",
      "  0.04911304  0.01692539  0.017827   -0.02360869 -0.03907128  0.0054693\n",
      "  0.03592725 -0.04129579 -0.05110811  0.05048424  0.01338658 -0.06962405\n",
      " -0.05260751  0.02823756 -0.01775637 -0.02082027  0.0038547  -0.06630673\n",
      " -0.02668957  0.00043902 -0.0162791   0.02789133  0.05028972  0.03459032\n",
      " -0.05370476  0.03950523  0.00895611  0.03521341 -0.01680934 -0.05544603\n",
      "  0.04528452 -0.04759531 -0.06803501  0.0465601  -0.05383831 -0.02985243\n",
      "  0.04797475 -0.03189937 -0.04297222  0.00343833 -0.0134342  -0.00264293\n",
      "  0.07915509 -0.03114969  0.0326178  -0.04163603 -0.02340098 -0.01881\n",
      " -0.07161128  0.06366799 -0.05452851 -0.04838847  0.0300818  -0.04663074\n",
      " -0.08759539  0.08257022 -0.03363619  0.05163511 -0.03975829 -0.05609583\n",
      " -0.02772727 -0.00689263  0.00714199 -0.09595744  0.01104475  0.05637866\n",
      "  0.03615608 -0.02920652  0.01123847  0.05871916 -0.06588513  0.00319342\n",
      "  0.01796551  0.07878967  0.02640141 -0.00767147  0.00845381 -0.02461743\n",
      "  0.0217002  -0.02998989 -0.00863426  0.04673233  0.0806563  -0.0055741\n",
      "  0.00767275 -0.00821625  0.07989199  0.08597022  0.05129911  0.01406686\n",
      " -0.01903579  0.05148869 -0.02773532 -0.058621   -0.03774747  0.02019465\n",
      "  0.03153784 -0.07280301 -0.03707727 -0.01726768 -0.02204005 -0.00050084\n",
      " -0.02079839 -0.06563533  0.05195575  0.0773631   0.01343943  0.03339778\n",
      " -0.01032145  0.02373341  0.05223278 -0.02814555  0.0339534  -0.03533981\n",
      "  0.02461631 -0.09233128 -0.00012531  0.03016129 -0.04237779  0.02223985\n",
      "  0.00415565  0.01719409 -0.00132601 -0.02191289 -0.01218892 -0.00234324\n",
      "  0.00306991 -0.00494174 -0.00306617  0.0065529  -0.01413226 -0.04437727\n",
      " -0.08545107 -0.0854802  -0.0536548   0.0143931  -0.04496573 -0.06894653\n",
      " -0.02291687 -0.07278566 -0.04186203  0.04963672  0.02059568  0.01533608\n",
      " -0.03470881  0.03012617  0.03987175  0.07070769  0.04680476 -0.02262687\n",
      "  0.06785166 -0.01899502 -0.08326992  0.00565323  0.08069143 -0.00195709\n",
      " -0.01779874  0.00565629 -0.07600196 -0.00482889 -0.02934678 -0.0758536\n",
      "  0.04919725 -0.03087111 -0.0909997  -0.02451992 -0.00027676 -0.01874572\n",
      " -0.04656482 -0.01809662  0.06168566 -0.00699502 -0.00675635  0.05648398\n",
      " -0.00716388  0.01167141  0.02355717 -0.04924569 -0.00277541 -0.02061227\n",
      " -0.00609973  0.09385081 -0.00138628  0.07769062 -0.05638949  0.01797198\n",
      " -0.06305318 -0.00969102 -0.01598935 -0.04511287 -0.05543344 -0.00505934\n",
      " -0.06570259  0.00506644 -0.01819512 -0.06391877 -0.02591481  0.03963347\n",
      " -0.00881939  0.00436385 -0.00131395  0.07121481  0.02527705 -0.00054301\n",
      " -0.01459014 -0.02913878 -0.03637543 -0.02431953 -0.00744596  0.02153585\n",
      "  0.05178958  0.0329645  -0.07554181 -0.02188813 -0.05179331 -0.02884508\n",
      "  0.01252533  0.06617398  0.05274093 -0.00906113 -0.00513657 -0.0132899\n",
      " -0.00474513  0.00262938 -0.06859916  0.04438871 -0.0116425  -0.02393564\n",
      "  0.01987875 -0.0688971   0.00199376 -0.01358856 -0.04236961  0.02230767\n",
      " -0.04842482  0.0786877  -0.0655679   0.05500342 -0.01444769  0.00029481\n",
      "  0.03304757  0.06593455 -0.03330807 -0.01963177  0.01405097  0.04565126\n",
      "  0.02153062 -0.02031881 -0.01489075  0.06568865 -0.06794996  0.01543074\n",
      " -0.04978345  0.04341813 -0.00131663 -0.01310433  0.02182266  0.00782998\n",
      " -0.07267593  0.02633631 -0.03988462 -0.02851778  0.03972638  0.08574647\n",
      "  0.0140261   0.01597632  0.04128186  0.01087891  0.04136454  0.02767804\n",
      " -0.00628061 -0.07900773 -0.01815526  0.0188853  -0.04135478  0.00869813\n",
      "  0.01140824  0.09259156 -0.07352533 -0.0328253  -0.00164992 -0.06241552\n",
      " -0.05872137  0.03013061  0.02801298 -0.02560498  0.03909744 -0.01020048\n",
      " -0.01120946  0.00894779  0.01932822 -0.08134083  0.04405494 -0.06327148\n",
      " -0.05281833  0.0069471  -0.03950996  0.04284582  0.06991518 -0.03723548\n",
      "  0.05309306  0.00441463 -0.06918003  0.06062165  0.05684426 -0.03209745\n",
      " -0.06266201  0.07832886  0.00845697 -0.01909634 -0.00220503  0.06124101\n",
      "  0.04131973 -0.05983323 -0.01824036 -0.02107269 -0.02697336 -0.07038907\n",
      " -0.02832131  0.04804677], shape=(512,), dtype=float32) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.ii) USE\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embeddings = embed(sentences)\n",
    "print(embeddings, '\\n\\n')\n",
    "for i in range(2):\n",
    "    print('Sentence :')\n",
    "    print(sentences[i])\n",
    "    print('Converted to :')\n",
    "    print(embeddings[i], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. iii) ELMO\n",
    "\n",
    "# elmo=hub.Module(\"https://tfhub.dev/google/elmo/3\",trainable=True)\n",
    "# embeddings=elmo(sentences, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "# init=tf.initialize_all_variables()\n",
    "# sess=tf.Session()\n",
    "# sess.run(init)\n",
    "\n",
    "# print(sess.run(embeddings[0]))\n",
    "\n",
    "\n",
    "# Execution Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape= torch.Size([1, 171])\n",
      "tensor([[   32,  7322,   318,   257,  2168,   286, 13439,   326,   389,  8389,\n",
      "           290, 24870,    11,   290,   389,   477,  3519,   284,   257,  2060,\n",
      "          7243,    13, 16699,   790,  3704,   286,  3597,   345,   466,   326,\n",
      "           318,  2392,   621,   257,  1178, 13439,   815,   307,  8389,   656,\n",
      "         23549,    13,   770,   318,   780, 23549,   905,   257,  9173,   810,\n",
      "           262, 45944,  3279,   286,   281, 14268,  2221,   290,   886,    11,\n",
      "           290,  4145,  1037,   262,  9173,   766,   262,  4009,   286,   262,\n",
      "         14268,   290, 13180,   663,  1388,  2173,    13,  2547,  6111,    82,\n",
      "           460,  3994,   867,  1180,  6982,   286,  1321,    13,   317,  7322,\n",
      "           714,  3994,   257,  2168,   286,  4506,  6096,   393,   257,  2060,\n",
      "           890, 20936,   286,   257,  2276,   966,    13,   632,  1244,  6901,\n",
      "           257,  1295,    11,  2095,    11,   393,  1429,    26,  6664,   378,\n",
      "           257,  2168,   286,  2995,    26,  8996,   393,  6273,   734,   393,\n",
      "           517,  1243,    26, 36509,  3709,   656,  9376,    26,   393,  6901,\n",
      "          5640,   290,  3048,    13, 22250,   286,   262,  1611,   286,  1321,\n",
      "           484,  3994,    11,   477, 23549,  2648,  1728,  9695,    13,  1881,\n",
      "           286,   262,   749,  1593,   286,   777,   318,   257,  7243,  6827,\n",
      "            13]])\n"
     ]
    }
   ],
   "source": [
    "# 1.iv) GPT2\n",
    "\n",
    "gp2tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2-large')\n",
    "model = transformers.GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
    "res_vectors = gp2tokenizer.encode(string, add_special_tokens=False, return_tensors=\"pt\")\n",
    "print(\"shape=\", res_vectors.shape)\n",
    "print(res_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.58439595  0.03570241  0.07089429 ...  0.16468506  0.01362591\n",
      "  -0.17049454]\n",
      " [ 0.5674903  -0.03022472  0.14544438 ...  0.08465072  0.04284173\n",
      "   0.03154207]\n",
      " [ 0.83034104  0.16388969 -0.03244966 ... -0.20251456  0.12385168\n",
      "   0.08940062]\n",
      " ...\n",
      " [ 0.4393374   0.02327457  0.12449443 ...  0.05474888 -0.09519409\n",
      "   0.00303834]\n",
      " [ 0.2909918   0.06627773  0.08403497 ... -0.10017543 -0.11646989\n",
      "   0.00867226]\n",
      " [ 0.5081561  -0.04534546  0.09999924 ...  0.06375446 -0.00892024\n",
      "  -0.03128232]], shape=(8, 128), dtype=float32)\n",
      "shape= (128,)\n",
      "The sentence in the paragraph:\n",
      " A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      "is converted into vector as :\n",
      " tf.Tensor(\n",
      "[ 0.58439595  0.03570241  0.07089429  0.07733776 -0.01214658 -0.12435579\n",
      " -0.07824828 -0.00274544 -0.17964575  0.21627969  0.03844824 -0.19277166\n",
      " -0.12646586  0.02667335 -0.13363229 -0.00374018 -0.06618838  0.00353754\n",
      " -0.21084203  0.18731229  0.06417363  0.03025784  0.01986333 -0.08417947\n",
      "  0.03461034 -0.10283548 -0.0499575  -0.07064839 -0.04805086  0.01945524\n",
      " -0.00223823 -0.05097701 -0.06611909 -0.20404741  0.0077603  -0.030263\n",
      "  0.045775   -0.12902436 -0.01877959  0.01619794  0.11104539 -0.08053494\n",
      "  0.23449406 -0.0133885  -0.07351163  0.15601118  0.01348254 -0.12100593\n",
      " -0.0793598  -0.02779575  0.01043605 -0.05894459  0.05691529  0.06368439\n",
      "  0.0845022   0.00101441  0.09372724 -0.0798301   0.05913398 -0.1558554\n",
      " -0.10184948 -0.02461847 -0.02784929 -0.08858608  0.03941965 -0.16783947\n",
      " -0.14578974 -0.02660521  0.14279118 -0.07796778  0.16825287 -0.06649883\n",
      " -0.05502456 -0.05567321 -0.07227787 -0.02554577 -0.21921757 -0.12569019\n",
      " -0.12072967 -0.09969082 -0.01872542 -0.07315438  0.02047394  0.08561355\n",
      " -0.09803957 -0.0105774  -0.07032494  0.11166418  0.40513557  0.21004194\n",
      " -0.06189978  0.03889223 -0.08983729 -0.03319109 -0.0035341   0.08772231\n",
      "  0.10927039 -0.10206924 -0.14698724  0.09524962  0.0152119   0.08549073\n",
      "  0.09397376  0.18190913  0.11837611 -0.02253025  0.1460779  -0.06170215\n",
      " -0.05503973  0.0625353  -0.22137204 -0.00889415 -0.09505872 -0.11496251\n",
      "  0.19664201 -0.17894565 -0.0801039  -0.09435873 -0.01823526 -0.02143514\n",
      "  0.07827251 -0.06584725 -0.0418337  -0.18853487  0.03571585  0.16468506\n",
      "  0.01362591 -0.17049454], shape=(128,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 1.v) Sentence-BERT\n",
    "\n",
    "bert = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
    "embeddings = bert(sentences)\n",
    "print(embeddings)\n",
    "print(\"shape=\",embeddings[0].shape)\n",
    "print(\"The sentence in the paragraph:\\n\",sentences[0],\"\\nis converted into vector as :\\n\", embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two CARDINAL\n",
      "One CARDINAL\n",
      "Countries, cities, states\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points. Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the most important of these is a topic sentence.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 2) Named Entity Recognition\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "res = nlp(string)\n",
    "\n",
    "for word in res.ents:\n",
    "    print(word.text,word.label_)\n",
    "    \n",
    "print(spacy.explain('GPE'))\n",
    "\n",
    "print(displacy.render(res,style=\"ent\",jupyter=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      " \n",
      "Sentence2= A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      "\n",
      "similarity =  1.0000001\n",
      " ----------------------------- \n",
      "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      " \n",
      "Sentence2= Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. \n",
      "\n",
      "similarity =  0.6477538\n",
      " ----------------------------- \n",
      "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      " \n",
      "Sentence2= This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points. \n",
      "\n",
      "similarity =  0.5238008\n",
      " ----------------------------- \n",
      "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      " \n",
      "Sentence2= Paragraphs can contain many different kinds of information. \n",
      "\n",
      "similarity =  0.58162665\n",
      " ----------------------------- \n",
      "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      " \n",
      "Sentence2= A paragraph could contain a series of brief examples or a single long illustration of a general point. \n",
      "\n",
      "similarity =  0.6927289\n",
      " ----------------------------- \n",
      "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      " \n",
      "Sentence2= It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. \n",
      "\n",
      "similarity =  0.50405544\n",
      " ----------------------------- \n",
      "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      " \n",
      "Sentence2= Regardless of the kind of information they contain, all paragraphs share certain characteristics. \n",
      "\n",
      "similarity =  0.7873839\n",
      " ----------------------------- \n",
      "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
      " \n",
      "Sentence2= One of the most important of these is a topic sentence. \n",
      "\n",
      "similarity =  0.54306334\n",
      " ----------------------------- \n"
     ]
    }
   ],
   "source": [
    "# 3) Find similar sentences (repeated sentences) from the above paragraph? (Cosine Similarity, use BERT to encode)\n",
    "\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "se_embeddings = sbert_model.encode(sentences)\n",
    "q1_vec= sbert_model.encode(sentences[0])\n",
    "\n",
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "for sent in sentences:\n",
    "    sim = cosine(q1_vec, sbert_model.encode([sent])[0])\n",
    "    # similarity == 1 - repeated sentence\n",
    "    # similarity > 0.5 - similar sentence\n",
    "    if sim>0.5:\n",
    "        print(\"Sentence1 =\",sentences[0],\"\\n \\nSentence2=\", sent, \"\\n\\nsimilarity = \", sim,end=\"\\n ----------------------------- \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('paragraph', 'NN'), ('series', 'NN'), ('sentences', 'NNS'), ('organized', 'VBN'), ('coherent', 'NN'), (',', ','), ('related', 'VBN'), ('single', 'JJ'), ('topic', 'NN'), ('.', '.')]\n",
      "[('Almost', 'RB'), ('every', 'DT'), ('piece', 'NN'), ('writing', 'VBG'), ('longer', 'JJR'), ('sentences', 'NNS'), ('organized', 'VBN'), ('paragraphs', 'NN'), ('.', '.')]\n",
      "[('This', 'DT'), ('paragraphs', 'NN'), ('show', 'NN'), ('reader', 'NN'), ('subdivisions', 'NNS'), ('essay', 'VBP'), ('begin', 'JJ'), ('end', 'NN'), (',', ','), ('thus', 'RB'), ('help', 'NN'), ('reader', 'VB'), ('see', 'VB'), ('organization', 'NN'), ('essay', 'VB'), ('grasp', 'NN'), ('main', 'JJ'), ('points', 'NNS'), ('.', '.')]\n",
      "[('Paragraphs', 'NNP'), ('contain', 'VBP'), ('many', 'JJ'), ('different', 'JJ'), ('kinds', 'NNS'), ('information', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('paragraph', 'NN'), ('could', 'MD'), ('contain', 'VB'), ('series', 'NN'), ('brief', 'NN'), ('examples', 'VBZ'), ('single', 'JJ'), ('long', 'JJ'), ('illustration', 'NN'), ('general', 'JJ'), ('point', 'NN'), ('.', '.')]\n",
      "[('It', 'PRP'), ('might', 'MD'), ('describe', 'VB'), ('place', 'NN'), (',', ','), ('character', 'NN'), (',', ','), ('process', 'NN'), (';', ':'), ('narrate', 'JJ'), ('series', 'NN'), ('events', 'NNS'), (';', ':'), ('compare', 'VB'), ('contrast', 'NN'), ('two', 'CD'), ('things', 'NNS'), (';', ':'), ('classify', 'VB'), ('items', 'NNS'), ('categories', 'NNS'), (';', ':'), ('describe', 'JJ'), ('causes', 'NNS'), ('effects', 'NNS'), ('.', '.')]\n",
      "[('Regardless', 'RB'), ('kind', 'NN'), ('information', 'NN'), ('contain', 'NN'), (',', ','), ('paragraphs', 'JJ'), ('share', 'NN'), ('certain', 'JJ'), ('characteristics', 'NNS'), ('.', '.')]\n",
      "[('One', 'CD'), ('important', 'JJ'), ('topic', 'NN'), ('sentence', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# 4) POS Tagging for Above Given Paragraph\n",
    "    \n",
    "tokenized = sent_tokenize(string)\n",
    "for i in tokenized:\n",
    "\n",
    "    wordList = nltk.word_tokenize(i)\n",
    "    wordList = [word for word in wordList if word not in stop_words]\n",
    "\n",
    "    tagged = nltk.pos_tag(wordList)\n",
    " \n",
    "    print(tagged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
